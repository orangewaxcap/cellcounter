{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell counter interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to provide a streamlined interface for cell counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, fixed\n",
    "from skimage import io, exposure, morphology\n",
    "import skimage\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CounterImage():\n",
    "    original_image: np.ndarray\n",
    "    processed_image: np.ndarray\n",
    "    channels_count: int\n",
    "    channels: dict\n",
    "    marks: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = widgets.FileUpload(multiple=False, description=\"Upload\")\n",
    "uf_name = widgets.Text(value=None,\n",
    "                       placeholder='no file loaded',\n",
    "                       description='',\n",
    "                       disabled=True\n",
    "                      )\n",
    "channel_selector = widgets.Dropdown(options=['(no file loaded)'],\n",
    "                                            value='(no file loaded)',\n",
    "                                            description='Channel:',\n",
    "                                            disabled=True\n",
    "                                           )\n",
    "\n",
    "image_store = widgets.Image()\n",
    "processed_image = None\n",
    "output = widgets.Output() #only used for debugging\n",
    "#output_image = widgets.Image(value=b'',format='png',width='300',height='400')\n",
    "\n",
    "\n",
    "def new_file_uploaded(change):\n",
    "    new_name = list(change['new'])[0]\n",
    "    new_img = io.imread(change['new'][new_name]['content'], plugin='imageio')\n",
    "    channels = [str(i+1) for i in range(new_img.shape[-1])]\n",
    "    channel_selector.options = channels\n",
    "    channel_selector.disabled = False\n",
    "    with output:\n",
    "        print(io.imread(change['new'][new_name]['content'], plugin='imageio').shape)\n",
    "        print([str(i+1) for i in range(new_img.shape[-1])])\n",
    "    uf_name.value = new_name\n",
    "    image_store.value = change['new'][new_name]['content']\n",
    "\n",
    "uploaded_file.observe(new_file_uploaded, 'value')\n",
    "filecontrol = widgets.HBox([uploaded_file,\n",
    "                            uf_name,\n",
    "                            #output,\n",
    "                            channel_selector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image(image_as_bytestream,\n",
    "                 lower_thresh=2, upper_thresh=98,\n",
    "                 filter_size=0, \n",
    "                 channel=0,\n",
    "                 cmap='viridis'\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Applies contrast stretching to an image, then\n",
    "    uses a white top-hat filter to remove small patches\n",
    "    of brightness that would cause false positives later.\n",
    "    \n",
    "    Input: image; values for min and max percentile\n",
    "    brightnesses to keep; size below which bright patches\n",
    "    will be removed; colourmap.\n",
    "    \n",
    "    Output: image, hopefully with most of the background stripped\n",
    "    out. If it's worked well, it'll look like bright blobs on a\n",
    "    dark background.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        channel = int(channel) - 1\n",
    "        image = io.imread(image_as_bytestream, plugin='imageio')[:,:,channel]\n",
    "\n",
    "        p2, p98 = np.percentile(image, (lower_thresh, upper_thresh))\n",
    "        img_rescale = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "        selem = morphology.disk(filter_size)\n",
    "        wht_tophat = morphology.white_tophat(img_rescale,selem=selem)\n",
    "        io.imshow(img_rescale - wht_tophat, cmap=cmap)\n",
    "        #can't believe I'm doing this\n",
    "        global processed_image\n",
    "        processed_image = img_rescale\n",
    "    except ValueError:\n",
    "        img_rescale=None\n",
    "        pass\n",
    "    \n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9ec6d8eb7446fd8b90d36e45551928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value={}, description='Upload'), Text(value='', disabled=True, placeholder='no file …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5701a814e54d02abe5a6d2dffdcad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=2, description='lower threshold', step=5, style=SliderStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c2384defb6413c94ad94dd8aed4810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_style = {'description_width': 'initial'}\n",
    "lower_thresh = widgets.IntSlider(min=0, max=100, step=5, value=2,\n",
    "                                 description='lower threshold', style=widget_style)\n",
    "upper_thresh = widgets.IntSlider(min=0, max=100, step=5, value=98,\n",
    "                                 description='upper threshold', style=widget_style)\n",
    "filter_size  = widgets.IntSlider(min=0, max=20, step=1, value=0,\n",
    "                                 description='filter size', style=widget_style)\n",
    "\n",
    "contrast_ui = widgets.VBox([lower_thresh, upper_thresh, filter_size])\n",
    "contrast_tweaking = widgets.interactive_output(adjust_image, {'lower_thresh': lower_thresh,\n",
    "                                                              'upper_thresh': upper_thresh,\n",
    "                                                              'filter_size': filter_size,\n",
    "                                                              'cmap': fixed('viridis'),\n",
    "                                                              'image_as_bytestream': image_store,\n",
    "                                                              'channel': channel_selector})\n",
    "\n",
    "display(filecontrol, contrast_ui, contrast_tweaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_blobs(original_image,\n",
    "                 processed_image,\n",
    "                 max_sigma=30,\n",
    "                 threshold=0.1\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Detects bright blobs in an image using the scikit-image\n",
    "    determinant of gaussian technique, then marks them on the\n",
    "    image.\n",
    "    \n",
    "    Input: original and processed images; max_sigma to determine \n",
    "    upper limit for blob size; threshold to determine how bright\n",
    "    something needs to be before it's identified as a blob.\n",
    "    \n",
    "    Output: displays image with red rings around detected blobs;\n",
    "    returns array of blob markers (y,x,radius).\n",
    "    \"\"\"\n",
    "    \n",
    "    blobs_dog = feature.blob_dog(processed_image,\n",
    "                                 max_sigma=max_sigma,\n",
    "                                 threshold=threshold\n",
    "                                )\n",
    "    blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2) #radius calcs\n",
    "    fig,axes = plt.subplots(ncols=2, figsize=(16,12))\n",
    "    ax_im_pairs = list(zip(axes,\n",
    "                           (processed_image,\n",
    "                            original_image),\n",
    "                           (True,True)\n",
    "                          ))\n",
    "    for ax,im,draw in ax_im_pairs:\n",
    "        ax.imshow(im)\n",
    "        if draw == True:\n",
    "            for blob in blobs_dog:\n",
    "                y,x,r = blob\n",
    "                c = plt.Circle((x, y), r,\n",
    "                               color='r',\n",
    "                               linewidth=2,\n",
    "                               fill=False\n",
    "                              )\n",
    "                ax.add_patch(c)\n",
    "    print(\"{} blobs detected.\".format(len(blobs_dog)))\n",
    "    \n",
    "    return blobs_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
